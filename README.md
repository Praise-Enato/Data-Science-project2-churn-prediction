# Customer Churn Prediction & CLV

Predict which telecom customers are likely to churn, estimate their Customer Lifetime Value (CLV), and prioritize retention with a Streamlit dashboard backed by scikit-learn models.

**Live app:** <https://praise-enato-churn-project.streamlit.app/>  
**Repo Clone URL:** <https://github.com/Praise-Enato/Data-Science-project2-churn-prediction.git>
**Demo Video URL:** 

## Project Highlights

- End-to-end churn modeling pipeline on the IBM Telco Customer Churn dataset with reproducible preprocessing and stratified splits.
- Logistic Regression as the primary model with Random Forest and XGBoost benchmarks, tuned to meet a recall >= 0.60 operating target.
- CLV estimation and quartile segmentation to align retention focus with customer value.
- Streamlit app with Predict, Model Performance, and CLV Overview tabs plus cached assets for fast responses.

## Repository Structure

.
├── app.py                  # Streamlit entry point

├── data/

│   ├── raw/                # optional raw dataset cache; pulled on demand

│   └── processed/          # train/val/test splits generated by data_prep.py

├── figures/                # saved plots for documentation and the app

├── models/                 # serialized pipelines, metrics, and ROC curves

├── notebooks/              # exploratory notebooks (not required to run)

├── requirements.txt

└── src/

    ├── data_prep.py        # download + clean + feature engineering + splits
    
    ├── clv_analysis.py     # CLV quartile summaries and figures
    
    ├── model_train.py      # train/evaluate Logistic Regression, RF, XGB
    
    ├── interpretability.py # global feature importance + ROC artifacts
    
    └── interpret.py        # local explanation helpers for the app

## Data & Feature Engineering

- Source dataset: [IBM Telco Customer Churn](https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv); downloaded automatically in `src/data_prep.py`.
- Cleans `TotalCharges`, imputes missing values, and engineers tenure buckets, service counts, risk flags, and CLV.
- Stratified 60/20/20 train, validation, and test splits are saved to `data/processed/`.

## Modeling & Evaluation

- Primary model: Logistic Regression (with one-hot encoding and scaling in a scikit-learn pipeline).
- Baselines: Random Forest and XGBoost for comparison.
- Operating policy: choose validation thresholds meeting recall >= 0.60 and report frozen metrics on the test set.
- Metrics and ROC curve JSON files live under `models/` for reuse in the Streamlit app.

## Model Performance

### Validation (chosen) vs Test (frozen threshold)

| Set                | Precision | Recall | F1-score | ROC-AUC | Threshold | TP  | FP  | TN  | FN |
|--------------------|-----------|--------|---------:|--------:|----------:|---:|---:|---:|---:|
| Validation (chosen)| **0.546** | **0.821** | **0.656** | **0.861** | **0.52** | 307 | 255 | 780 | 67 |
| Test (frozen thr.) | **0.530** | **0.791** | **0.635** | **0.833** | **0.52** | 296 | 263 | 772 | 78 |

> Threshold selected on validation to satisfy **recall ≥ 0.60** and maximize **F1**; frozen for test.

### Model comparison (Test)

| Model          | Precision | Recall | F1-score | ROC-AUC | Threshold |
|----------------|-----------|--------|---------:|--------:|----------:|
| **LOGREG**     | 0.558     | 0.682  | 0.614    | 0.839   | 0.61      |
| **RANDOM FOREST** | 0.536  | 0.735  | 0.620    | 0.835   | 0.54      |
| **XGBOOST**    | **0.530** | **0.791** | **0.635** | **0.833** | **0.52** |

> ROC overlay available in the app; higher AUC indicates better separability.

## Streamlit App

- **Predict tab:** Collect customer attributes, return churn probability, risk badge, CLV estimate, and a coefficient-based local explanation.
- **Model Performance tab:** Threshold-aware precision, recall, F1, ROC-AUC, confusion matrix, ROC overlays, and optional calibration.
- **CLV Overview tab:** CLV distribution, churn by quartile, and tailored retention takeaways.
- Uses `@st.cache_data` and `@st.cache_resource` to keep load times under roughly two seconds on Streamlit Community Cloud.

## Business Insights & Retention Actions

- **Contract term still dominates churn.** Month-to-month subscribers churn at **43%**, versus **3%** for two-year contracts and **11%** for one-year terms. Prioritize converting short-term customers to annual agreements with targeted incentives.
- **Billing automation halves churn.** Customers paying by electronic check churn at **46%** compared with **16%** for auto-pay methods. Embed auto-pay enrollments in retention plays, especially for at-risk fiber-optic users.
- **Value and support gaps drive attrition.** “High” CLV customers churn at **38%** (vs **9%** in the Premium tier) and internet customers without tech support churn at **42%** (vs **15%** with support). Focus retention spend on High/Medium CLV accounts lacking support add-ons.

## Getting Started

### 1. Set up a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 2. Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 3. Build local artifacts (only needed after data or code changes)

```bash
python -m src.data_prep         # downloads and preprocesses the dataset
python -m src.clv_analysis      # generates CLV summaries and plots
python -m src.model_train       # fits models and saves metrics and pipelines
python -m src.interpretability  # optional: refresh global interpretation plots
```

### 4. Launch the Streamlit app

```bash
streamlit run app.py
```

## Deployment Notes

- Targeted for Streamlit Community Cloud; push regenerated artifacts (`models/`, `figures/`, `data/processed/`) before deploying.
- Configure Streamlit secrets or environment variables as needed; none are required by default.

## Troubleshooting

- If `src.data_prep` raises an HTTP error, verify your network connection and rerun the command.
- Regenerate artifacts after modifying feature engineering or model code to keep the deployed app consistent.
